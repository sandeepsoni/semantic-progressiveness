{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import sys\n",
    "import numpy as np\n",
    "if \"../\" not in sys.path: sys.path.append (\"../\")\n",
    "from modules.semshift import embeddings, alignment, measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "STATS_DIR = \"/hg191/corpora/legaldata/data/stats/\"\n",
    "MODELS_DIR = \"/hg191/corpora/legaldata/models/\"\n",
    "NAMES_FILES = [os.path.join(STATS_DIR, \"names.neural\"), os.path.join(STATS_DIR, \"names.tagging\")]\n",
    "SCORES_FILES = [os.path.join (STATS_DIR, \"V.{0}.scores\".format (seed)) for seed in [100, 200, 300, 400, 500]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readNames (filenames):\n",
    "    names = set()\n",
    "    for filename in filenames:\n",
    "        with open (filename) as fin:\n",
    "            for line in fin:\n",
    "                names.add(line.strip())\n",
    "    return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = readNames (NAMES_FILES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "early100 = embeddings.TrainedModel(os.path.join(MODELS_DIR, \"sgns.500K.early.100.model\"))\n",
    "early200 = embeddings.TrainedModel(os.path.join(MODELS_DIR, \"sgns.500K.early.200.model\"))\n",
    "early300 = embeddings.TrainedModel(os.path.join(MODELS_DIR, \"sgns.500K.early.300.model\"))\n",
    "early400 = embeddings.TrainedModel(os.path.join(MODELS_DIR, \"sgns.500K.early.400.model\"))\n",
    "early500 = embeddings.TrainedModel(os.path.join(MODELS_DIR, \"sgns.500K.early.500.model\"))\n",
    "\n",
    "later100 = embeddings.TrainedModel(os.path.join(MODELS_DIR, \"sgns.500K.later.100.model\"))\n",
    "later200 = embeddings.TrainedModel(os.path.join(MODELS_DIR, \"sgns.500K.later.200.model\"))\n",
    "later300 = embeddings.TrainedModel(os.path.join(MODELS_DIR, \"sgns.500K.later.300.model\"))\n",
    "later400 = embeddings.TrainedModel(os.path.join(MODELS_DIR, \"sgns.500K.later.400.model\"))\n",
    "later500 = embeddings.TrainedModel(os.path.join(MODELS_DIR, \"sgns.500K.later.500.model\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08591904\n"
     ]
    }
   ],
   "source": [
    "print(np.dot(early100.m.wv.vectors[0,:], later100.m.wv.vectors[0,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alignTwoModels (first_model, second_model):\n",
    "    second_model.m = alignment.smart_procrustes_align_gensim(first_model.m, second_model.m)\n",
    "    return first_model, second_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "early100_, later100_ = alignTwoModels (early100, later100)\n",
    "early200_, later200_ = alignTwoModels (early200, later200)\n",
    "early300_, later300_ = alignTwoModels (early300, later300)\n",
    "early400_, later400_ = alignTwoModels (early400, later400)\n",
    "early500_, later500_ = alignTwoModels (early500, later500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6740516\n"
     ]
    }
   ],
   "source": [
    "print(np.dot(early100.m.wv.vectors[0,:], later100.m.wv.vectors[0,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vEarly100 = {key for key in early100_.m.wv.vocab.keys()}\n",
    "vLater100 = {key for key in early100_.m.wv.vocab.keys()}\n",
    "vCommon100 = vEarly100 & vLater100\n",
    "\n",
    "vEarly200 = {key for key in early200_.m.wv.vocab.keys()}\n",
    "vLater200 = {key for key in early200_.m.wv.vocab.keys()}\n",
    "vCommon200 = vEarly200 & vLater200\n",
    "\n",
    "vEarly300 = {key for key in early300_.m.wv.vocab.keys()}\n",
    "vLater300 = {key for key in early300_.m.wv.vocab.keys()}\n",
    "vCommon300 = vEarly300 & vLater300\n",
    "\n",
    "vEarly400 = {key for key in early400_.m.wv.vocab.keys()}\n",
    "vLater400 = {key for key in early400_.m.wv.vocab.keys()}\n",
    "vCommon400 = vEarly400 & vLater400\n",
    "\n",
    "vEarly500 = {key for key in early500_.m.wv.vocab.keys()}\n",
    "vLater500 = {key for key in early500_.m.wv.vocab.keys()}\n",
    "vCommon500 = vEarly500 & vLater500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We already constructed a list of words for each of these models above to have changed in meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoresAsDict (filename):\n",
    "    asdict = {}\n",
    "    with open (filename) as fin:\n",
    "        for line in fin:\n",
    "            parts = line.strip().split (\",\")\n",
    "            asdict[parts[0]] = float(parts[1])\n",
    "    return asdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordscores = dict ()\n",
    "for scorefile in SCORES_FILES:\n",
    "    seednum = int(os.path.splitext(os.path.basename (scorefile))[0].split(\".\")[1])\n",
    "    wordscores[seednum] = scoresAsDict (scorefile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply a very conservative heuristic to get meaningful but high precision sublist of change words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getKeepAndThrowLists (scoresasdict, emod, lmod, keep_freq=25, throw_freq=75, frac=0.8, topn=50, k=10000):\n",
    "    throw_words = list ()\n",
    "    kept_words = list ()\n",
    "    \n",
    "    for word, score in sorted (scoresasdict.items(), key=lambda x:x[1], reverse=True)[0:k]:\n",
    "        e_num_neighbors = len ([n for n, sim in emod.wv.most_similar(word, topn=topn) if n in scoresasdict])\n",
    "        l_num_neighbors = len ([n for n, sim in lmod.wv.most_similar(word, topn=topn) if n in scoresasdict])\n",
    "        \n",
    "        if e_num_neighbors >= int(frac*topn) and l_num_neighbors >= int (frac*topn):\n",
    "            if emod.wv.vocab[word].count >= keep_freq and lmod.wv.vocab[word].count >= keep_freq:\n",
    "                kept_words.append (word)\n",
    "            else:\n",
    "                throw_words.append (word)\n",
    "        else:\n",
    "            if emod.wv.vocab[word].count >= throw_freq and lmod.wv.vocab[word].count >= throw_freq:\n",
    "                kept_words.append (word) #keep a word if its high frequency (high-frequency bias)\n",
    "            else:\n",
    "                throw_words.append (word) #throw a word if its not high frequency \n",
    "    \n",
    "    return kept_words, throw_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nethome/ssoni30/venvs/py36/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    }
   ],
   "source": [
    "seednum = 100\n",
    "k100, t100 = getKeepAndThrowLists (wordscores[seednum], early100_.m, later100_.m, throw_freq=50, frac=0.8, topn=50, k=10000)\n",
    "\n",
    "seednum = 200\n",
    "k200, t200 = getKeepAndThrowLists (wordscores[seednum], early200_.m, later200_.m, throw_freq=50, frac=0.8, topn=50, k=10000)\n",
    "\n",
    "seednum = 300\n",
    "k300, t300 = getKeepAndThrowLists (wordscores[seednum], early300_.m, later300_.m, throw_freq=50, frac=0.8, topn=50, k=10000)\n",
    "\n",
    "seednum = 400\n",
    "k400, t400 = getKeepAndThrowLists (wordscores[seednum], early400_.m, later400_.m, throw_freq=50, frac=0.8, topn=50, k=10000)\n",
    "\n",
    "seednum = 500\n",
    "k500, t500 = getKeepAndThrowLists (wordscores[seednum], early500_.m, later500_.m, throw_freq=50, frac=0.8, topn=50, k=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "keeplists = [k100, k200, k300, k400, k500]\n",
    "throwlists = [t100, t200, t300, t400, t500]\n",
    "\n",
    "seednums = [100, 200, 300, 400, 500]\n",
    "\n",
    "for i, seednum in enumerate(seednums):\n",
    "    with open (os.path.join (STATS_DIR, \"V.{0}.keeplist\".format (seednum)), \"w\") as fout:\n",
    "        for w in keeplists[i]:\n",
    "            fout.write (\"{0}\\n\".format (w))\n",
    "    \n",
    "    with open (os.path.join (STATS_DIR, \"V.{0}.throwlist\".format (seednum)), \"w\") as fout:\n",
    "        for w in throwlists[i]:\n",
    "            fout.write (\"{0}\\n\".format (w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_neighbors (emds, word, topn=50):\n",
    "    return [neighbor for neighbor, similarity in emds.wv.most_similar(word, topn=topn)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nethome/ssoni30/venvs/py36/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    }
   ],
   "source": [
    "with open (os.path.join (STATS_DIR, \"V.100.nns\"), \"w\") as fout:\n",
    "    for i,w in enumerate(keeplists[0]):\n",
    "        fout.write (\"Rank: {0}, Word:{1}\\n\".format(i, w))\n",
    "        fout.write (\"Early:\" + \",\".join(nearest_neighbors(early100_.m, w, topn=10)) + \"\\n\")\n",
    "        fout.write (\"Later:\" + \",\".join(nearest_neighbors(later100_.m, w, topn=10)) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1643\n"
     ]
    }
   ],
   "source": [
    "#[w for w in keeplists[0] if early100_.m.wv.vocab[w].count <= 25 and later100_.m.wv.vocab[w].count <= 25]\n",
    "print (len([w for w in throwlists[0] if early100_.m.wv.vocab[w].count >= 50 and later100_.m.wv.vocab[w].count >= 50]))\n",
    "#sum([early100_.m.wv.vocab[w].count >= 100 and later100_.m.wv.vocab[w].count >= 100 for w in throwlists[0]]), len (throwlists[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early100_.m.wv.vocab[\"kingpin\"].count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ahall', 'rhall', 'ehall', 'suah', 'aad', 'sor', 'aball', 'auoh', 'ior', 'suoh']\n",
      "['nass', 'mous', 'riehm', 'impropriety', 'unadmitted', 'neidhardt', 'impugned', 'canvass', 'unproven', 'blessed']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nethome/ssoni30/venvs/py36/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    }
   ],
   "source": [
    "print(nearest_neighbors(early100_.m, \"shsll\", topn=10))\n",
    "print(nearest_neighbors(later100_.m, \"shsll\", topn=10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
